#!/usr/bin/env python

# CS4242 Social Media Computing
# Assignment 1
# See LICENSE for details

# Path to the training set of tweets.

# Stopword sources, in order.
stopword_sources = [
    'nltk:english',
    'file:./dataset/stopwords.smartdatacollective.com.txt'
]

# Path to a vocabulary normalization map.
vocab_map = './dataset/normalization_map.emnlp.txt'

# Should we classify tweets from an actual source, or from a file?
# tweet_source = "twitter"
# tweet_source = "link"
tweet_source = "file"

# If we are classifying tweets from a file, then these parameters are required.
tweet_file = "./dataset/tweets/nus/nus_pos.txt"

# If we are classifying tweets from the actual source, then these API
# parameters are required.
oauth_consumer_key = ""
oauth_consumer_secret = ""

oauth_token_key = ""
oauth_token_secret = ""

# vim: set ts=4 sw=4 et:
